{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from circuit_tracer import ReplacementModel, attribute\n",
    "from circuit_tracer.utils import create_graph_files\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e318f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./wikineural-multilingual-ner.pt\"\n",
    "model = ReplacementModel.from_pretrained(model_name, model_name.split(\"/\")[-1], dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \" \".join([\"The\", \"National\", \"Congress\", \"of\", \"American\", \"Indians\", \"was\", \"founded\", \"in\", \"1944\", \"in\", \"response\", \"to\", \"assimilation\", \"policies\", \"being\", \"imposed\", \"on\", \"tribes\", \"by\", \"the\", \"federal\", \"government\", \".\"])  # What you want to get the graph for\n",
    "max_n_logits = 10   # How many logits to attribute from, max. We attribute to min(max_n_logits, n_logits_to_reach_desired_log_prob); see below for the latter\n",
    "desired_logit_prob = 0.95  # Attribution will attribute from the minimum number of logits needed to reach this probability mass (or max_n_logits, whichever is lower)\n",
    "max_feature_nodes = model.config.d_model  # Only attribute from this number of feature nodes, max. Lower is faster, but you will lose more of the graph. None means no limit.\n",
    "batch_size=128  # Batch size when attributing\n",
    "offload='cpu' # Offload various parts of the model during attribution to save memory. Can be 'disk', 'cpu', or None (keep on GPU)\n",
    "verbose = True  # Whether to display a tqdm progress bar and timing report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77721265",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = attribute(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    max_n_logits=max_n_logits,\n",
    "    desired_logit_prob=desired_logit_prob,\n",
    "    batch_size=batch_size,\n",
    "    max_feature_nodes=max_feature_nodes,\n",
    "    offload=offload,\n",
    "    verbose=verbose\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
